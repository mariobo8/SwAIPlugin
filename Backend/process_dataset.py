#!/usr/bin/env python3
"""
Training Data Processor for SolidWorks AI

This script processes the raw data generated by the FeatureWalker (C# component)
and uses GPT-4o to synthesize training pairs (User Prompt -> JSON Command).

Usage:
    python process_dataset.py

Requirements:
    - openai
    - python-dotenv

Environment Variables:
    - OPENAI_API_KEY: Your OpenAI API key
"""

import os
import sys
import json
import base64
import time
from pathlib import Path
from datetime import datetime

# Load environment variables
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    print("‚ö†Ô∏è  python-dotenv not installed. Using system environment variables.")
    print("   Install with: pip install python-dotenv")

# Try to import OpenAI
try:
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False
    print("‚ùå OpenAI package not installed.")
    print("   Install with: pip install openai")
    sys.exit(1)

# Configuration
SCRIPT_DIR = Path(__file__).parent.absolute()
PROJECT_ROOT = SCRIPT_DIR.parent
TRAINING_OUTPUT_DIR = PROJECT_ROOT / "Training_Output_Data"
TRAIN_JSONL_PATH = PROJECT_ROOT / "train.jsonl"

# OpenAI Configuration
MODEL = "gpt-4o"  # Vision model for image analysis
MAX_RETRIES = 3
RETRY_DELAY = 2  # seconds

# System prompt for GPT-4o to generate training pairs
SYNTHESIS_SYSTEM_PROMPT = """You are a training data generator for a SolidWorks AI assistant.

Your task is to analyze the provided information about a SolidWorks feature operation and generate:
1. A natural language user request (what a human would say)
2. The corresponding JSON command that the AI should output

You will receive:
- A "before" image showing the model BEFORE the feature was applied
- An "after" image showing the model AFTER the feature was applied
- Raw metadata extracted from the feature definition (dimensions, parameters, sketch data)

IMPORTANT GUIDELINES:

1. UNIT CONVERSION: SolidWorks internal units are METERS. All dimensions in data.txt are in METERS.
   - Convert to MILLIMETERS for the user message and JSON command
   - Example: 0.025 meters = 25 mm

2. PLANE/REFERENCE INFO IS CRITICAL: Always include WHERE the feature was created:
   - Which plane: "Front Plane", "Top Plane", "Right Plane"
   - Or which face: "top face", "front face of the box", etc.
   - Example: "Create a 50mm extrusion on the Front Plane" NOT just "Create a 50mm extrusion"

3. USER MESSAGE STYLE: Write natural, conversational requests that include LOCATION:
   - "On the Front Plane, sketch a 100x50mm rectangle and extrude it 25mm"
   - "On the top face, create a 10mm diameter hole"
   - "Add a 3mm fillet to all vertical edges"
   - "Create a 100x50x25mm box starting from the Top Plane"
   - "On the right face of the cylinder, sketch a 20mm square and cut 5mm deep"

4. JSON COMMAND FORMAT: Use this exact structure and ALWAYS include the plane parameter:
{
    "action": "create" | "create_part" | "modify" | "delete",
    "type": "box" | "cylinder" | "extrusion" | "cut" | "hole" | "threaded_hole" | "fillet" | "chamfer" | "shell" | "pattern" | etc.,
    "parameters": {
        "plane": "Front Plane" | "Top Plane" | "Right Plane" | "top_face" | "front_face" | etc.,
        // Include all relevant dimensions in mm
        // Always include "units": "mm"
    }
}

Example with plane:
{
    "action": "create",
    "type": "box",
    "parameters": {
        "plane": "Front Plane",
        "width": 100,
        "height": 50,
        "depth": 25,
        "units": "mm"
    }
}

4. BE SPECIFIC: Include actual dimensions from the metadata. Don't use vague terms like "small" or "large".

5. INFER INTENT: Based on the visual change and metadata, determine what the user likely wanted to achieve.

6. HANDLE EDGE CASES:
   - If the feature type isn't directly supported, map to the closest available command
   - If sketch data shows a rectangle -> likely an extrusion
   - If sketch data shows a circle -> likely a cylinder or hole

Respond with ONLY a valid JSON object in this format:
{
    "user_text": "The natural language request the user would make",
    "assistant_json": { /* The JSON command */ }
}

Do not include any other text, explanation, or markdown formatting."""


def load_image_as_base64(image_path: Path) -> str:
    """Load an image file and convert to base64."""
    try:
        with open(image_path, "rb") as f:
            return base64.standard_b64encode(f.read()).decode("utf-8")
    except Exception as e:
        print(f"    ‚ö†Ô∏è  Could not load image {image_path}: {e}")
        return None


def read_metadata(data_path: Path) -> str:
    """Read the metadata text file."""
    try:
        with open(data_path, "r", encoding="utf-8") as f:
            return f.read()
    except Exception as e:
        print(f"    ‚ö†Ô∏è  Could not read metadata {data_path}: {e}")
        return ""


def process_feature_step(client: OpenAI, step_dir: Path) -> dict:
    """
    Process a single feature step directory.
    
    Args:
        client: OpenAI client instance
        step_dir: Path to the step directory containing before.png, after.png, sketch.png, data.txt
        
    Returns:
        dict with user_text and assistant_json, or None on failure
    """
    before_path = step_dir / "before.png"
    after_path = step_dir / "after.png"
    sketch_path = step_dir / "sketch.png"
    data_path = step_dir / "data.txt"
    
    # Check required files exist
    if not before_path.exists():
        print(f"    ‚ö†Ô∏è  Missing before.png")
        return None
    if not after_path.exists():
        print(f"    ‚ö†Ô∏è  Missing after.png")
        return None
    if not data_path.exists():
        print(f"    ‚ö†Ô∏è  Missing data.txt")
        return None
    
    # Load images
    before_b64 = load_image_as_base64(before_path)
    after_b64 = load_image_as_base64(after_path)
    sketch_b64 = load_image_as_base64(sketch_path) if sketch_path.exists() else None
    
    if not before_b64 or not after_b64:
        return None
    
    # Read metadata
    metadata = read_metadata(data_path)
    
    # Build the prompt
    sketch_instructions = ""
    if sketch_b64:
        sketch_instructions = """
The THIRD image is the SKETCH view showing the 2D profile with dimensions.
Use the sketch dimensions to get EXACT measurements for your JSON command."""
    
    user_prompt = f"""Analyze this SolidWorks feature operation:

=== FEATURE METADATA ===
{metadata}

Look at the images to understand what was created:
- Image 1: BEFORE the feature (3D view)
- Image 2: AFTER the feature (3D view){sketch_instructions}

Generate a training pair with:
1. A natural language user request (what a human would say)
2. The corresponding JSON command with EXACT dimensions

IMPORTANT: 
- Convert all dimensions from METERS to MILLIMETERS!
- Use the EXACT dimensions shown in the sketch/metadata
- Include position coordinates if visible in the sketch"""

    # Build image content for the API call
    image_content = [
        {
            "type": "image_url",
            "image_url": {
                "url": f"data:image/png;base64,{before_b64}",
                "detail": "high"
            }
        },
        {
            "type": "image_url",
            "image_url": {
                "url": f"data:image/png;base64,{after_b64}",
                "detail": "high"
            }
        }
    ]
    
    # Add sketch image if available
    if sketch_b64:
        image_content.append({
            "type": "image_url",
            "image_url": {
                "url": f"data:image/png;base64,{sketch_b64}",
                "detail": "high"
            }
        })
    
    image_content.append({
        "type": "text",
        "text": user_prompt
    })

    # Call GPT-4o with vision
    for attempt in range(MAX_RETRIES):
        try:
            response = client.chat.completions.create(
                model=MODEL,
                messages=[
                    {"role": "system", "content": SYNTHESIS_SYSTEM_PROMPT},
                    {
                        "role": "user",
                        "content": image_content
                    }
                ],
                max_tokens=1000,
                temperature=0.7
            )
            
            # Parse the response
            content = response.choices[0].message.content.strip()
            
            # Try to extract JSON from the response
            # Handle potential markdown code blocks
            if content.startswith("```"):
                # Remove markdown code block
                lines = content.split("\n")
                content = "\n".join(lines[1:-1])
            
            result = json.loads(content)
            
            # Validate structure
            if "user_text" not in result or "assistant_json" not in result:
                print(f"    ‚ö†Ô∏è  Invalid response structure")
                continue
                
            return result
            
        except json.JSONDecodeError as e:
            print(f"    ‚ö†Ô∏è  JSON parse error (attempt {attempt + 1}): {e}")
            if attempt < MAX_RETRIES - 1:
                time.sleep(RETRY_DELAY)
        except Exception as e:
            print(f"    ‚ö†Ô∏è  API error (attempt {attempt + 1}): {e}")
            if attempt < MAX_RETRIES - 1:
                time.sleep(RETRY_DELAY)
    
    return None


def format_as_training_pair(user_text: str, assistant_json: dict) -> dict:
    """
    Format a training pair in OpenAI's fine-tuning JSONL format.
    
    The format is:
    {"messages": [{"role": "system", "content": "..."}, {"role": "user", "content": "..."}, {"role": "assistant", "content": "..."}]}
    """
    system_message = """You are a SolidWorks AI assistant. When users ask you to create or modify 3D geometry, respond with a JSON command that can be executed by the SolidWorks plugin.

Available actions: create, create_part, modify, delete
Available types: box, cylinder, extrusion, cut, hole, threaded_hole, fillet, chamfer, shell, pattern, boss_on_face, cut_on_face

Always include "units": "mm" in parameters. All dimensions should be in millimeters."""

    return {
        "messages": [
            {"role": "system", "content": system_message},
            {"role": "user", "content": user_text},
            {"role": "assistant", "content": json.dumps(assistant_json)}
        ]
    }


def process_dataset():
    """Main function to process all training data."""
    print("=" * 60)
    print("SolidWorks Training Data Processor")
    print("=" * 60)
    print(f"Started: {datetime.now()}")
    print()
    
    # Check API key
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        print("‚ùå OPENAI_API_KEY not found in environment variables.")
        print("   Create a .env file in the Backend folder with:")
        print("   OPENAI_API_KEY=your_api_key_here")
        return
    
    # Initialize OpenAI client
    client = OpenAI(api_key=api_key)
    print("‚úÖ OpenAI client initialized")
    
    # Check training output directory
    if not TRAINING_OUTPUT_DIR.exists():
        print(f"‚ùå Training output directory not found: {TRAINING_OUTPUT_DIR}")
        print("   Run the 'Generate Training Data' command in SolidWorks first.")
        return
    
    # Find all part directories
    part_dirs = [d for d in TRAINING_OUTPUT_DIR.iterdir() if d.is_dir()]
    
    if not part_dirs:
        print(f"‚ùå No part directories found in {TRAINING_OUTPUT_DIR}")
        return
    
    print(f"üìÅ Found {len(part_dirs)} part director(y/ies)")
    print()
    
    # Process each part
    training_pairs = []
    total_steps = 0
    successful_steps = 0
    
    for part_dir in sorted(part_dirs):
        part_name = part_dir.name
        print(f"üì¶ Processing: {part_name}")
        
        # Find all step directories (named like 000_FeatureName)
        step_dirs = sorted([d for d in part_dir.iterdir() if d.is_dir()])
        
        if not step_dirs:
            print(f"    ‚ö†Ô∏è  No step directories found")
            continue
        
        print(f"    Found {len(step_dirs)} feature step(s)")
        
        for step_dir in step_dirs:
            step_name = step_dir.name
            total_steps += 1
            
            print(f"    [{step_name}] ", end="", flush=True)
            
            result = process_feature_step(client, step_dir)
            
            if result:
                training_pair = format_as_training_pair(
                    result["user_text"],
                    result["assistant_json"]
                )
                training_pairs.append(training_pair)
                successful_steps += 1
                print("‚úÖ")
                
                # Also save individual result for debugging
                result_path = step_dir / "training_pair.json"
                with open(result_path, "w", encoding="utf-8") as f:
                    json.dump(result, f, indent=2)
            else:
                print("‚ùå")
        
        print()
    
    # Write the training file
    if training_pairs:
        print(f"üìù Writing {len(training_pairs)} training pairs to {TRAIN_JSONL_PATH}")
        
        with open(TRAIN_JSONL_PATH, "w", encoding="utf-8") as f:
            for pair in training_pairs:
                f.write(json.dumps(pair) + "\n")
        
        print("‚úÖ train.jsonl created successfully!")
    else:
        print("‚ö†Ô∏è  No training pairs were generated.")
    
    # Summary
    print()
    print("=" * 60)
    print("SUMMARY")
    print("=" * 60)
    print(f"Total parts processed: {len(part_dirs)}")
    print(f"Total feature steps: {total_steps}")
    print(f"Successful conversions: {successful_steps}")
    print(f"Failed conversions: {total_steps - successful_steps}")
    print(f"Output file: {TRAIN_JSONL_PATH}")
    print(f"Completed: {datetime.now()}")
    
    if training_pairs:
        print()
        print("üìã Next Steps:")
        print("   1. Review train.jsonl for quality")
        print("   2. Upload to OpenAI for fine-tuning:")
        print("      openai api fine_tunes.create -t train.jsonl -m gpt-3.5-turbo")
        print("   3. Or use the training file with your preferred training pipeline")


def main():
    """Entry point."""
    try:
        process_dataset()
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è  Process interrupted by user.")
        sys.exit(1)
    except Exception as e:
        print(f"\n‚ùå Unexpected error: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()

